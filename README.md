# 25年情報学ゼミ課題
このリポジトリは2025年情報学ゼミ期末課題に使用したコードを管理するものです。
## 1. 実装した生成モデルの説明

本プロジェクトで採用した生成モデルであるVQ-VAEは、エンコーダが抽出した連続的な特徴量を、あらかじめ学習されたコードブック内の最も近いベクトルへと置き換えるベクトル量子化によって情報を離散的に圧縮する。この量子化されたベクトルがデコーダへと入力され、元の画像を忠実に再現するように再構成が行われる仕組みである。

本モデルを選定した主な理由は、潜在変数を離散化することによって生成画像の品質を向上させられる点にある。従来のVAEは潜在変数が連続的であるために再構成画像がぼやける傾向にあるが、VQ-VAEは離散的なコードを介して特徴量を表現するため、細部まで鮮明な出力を得ることが可能となる。さらに、この量子化プロセスをネットワーク構造に組み込むことで、標準的なVAEで頻発する、潜在変数が学習に寄与しなくなる現象（事後分布崩壊）を構造的に回避し、学習を安定化させている。

これらの特性は、MNISTのような明確な幾何学的構造を持つデータセットから数字の構成要素を効率的に学習するのに適している。したがって、本課題の主目的である精緻な数字の生成や、形状の連続的な遷移を表現する「4」から「9」への補間において、VQ-VAEは適合性の高いモデルであると判断した。

## 2. プログラムの実行方法
### 環境構築  
* 必要なライブラリをインストールする。  
```python
pip install -r requirements.txt
```
### ディレクトリ構造
```text
vq-vae-project/  
├── configs/  
│   └── config.yaml           # ハイパーパラメータを一括管理  
├── models/  
│   ├── __init__.py           # 各クラスを外部から呼び出しやすくする  
│   ├── encoder.py            # 担当①: Encoderの実装  
│   ├── decoder.py            # 担当①: Decoderの実装  
│   ├── quantizer.py          # 担当②: VectorQuantizerの実装  
│   └── vqvae.py              # 担当④: 全体の結合（Modelクラス）  
├── utils/  
│   ├── __init__.py  
│   ├── dataset.py            # 担当③: DataLoaderの設定  
│   └── logger.py             # 担当③: 学習ログ（WandB等）の設定  
├── main.py                   # 担当③④: 学習実行スクリプト  
├── requirements.txt          # 使用ライブラリ（torch, pyyaml, einopsなど）  
└── .gitignore                # data/, outputs/, __pycache__/ を除外  
```
### 学習および評価の実行
* 以下のコマンドを実行することで、MNISTの学習、モデルの保存、および再構成・補間画像の生成が自動的に行われる。  
```
python main.py
```
設定の変更ハイパーパラメータ（学習率、埋め込み次元数等）は config.yaml を書き換えることで調整可能である。  

## 3. 課題 2 の結果と考察
### 実行結果
results/interp_4_to_9.png に、数字「4」から「9」へとモーフィングのように変化していく12段階の画像が保存される。

![結果](https://github.com/monenenho/VQ-VAE1/blob/main/results/interp_4_to_9.png) 
### 考察
生成された一連の補間画像を確認すると、以下の段階的な変化が観察できる。  
* 初期段階: 数字「4」の上部の開放部が、潜在空間上での $z_{9}$への接近に伴い、徐々に内側へ湾曲し始める。  
* 中間段階: 「4」の縦棒と横棒の交差部分が、数字「9」の閉じたループへと変化し、両方の数字の特徴を併せ持った中間的な字形が生成される。  
* 終盤段階: 数字「4」特有の角張った特徴が消失し、滑らかな曲線を持つ「9」の形状へと収束する。 

これらのことより、エンコーダが数字の骨格的特徴を精緻に抽出し、潜在空間の近傍へ適切に写像できていると考えられる。STEによる勾配伝播の最適化と、再初期化処理によるコードブック資源の有効活用が作用した結果、離散的な量子化を用いながらも、生成モデルとしての高い連続性と再現性が両立されたと推察される。